{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "def ocurrence_left(corpus, center, n):\n",
    "    v_out = []\n",
    "    L = len(corpus)\n",
    "    words = iter(corpus)\n",
    "    \n",
    "    for  word in range(0, len(corpus)):\n",
    "        w = next(words)\n",
    "        \n",
    "        if (w == center):\n",
    "            center_index = word\n",
    "            j =1\n",
    "            \n",
    "            while j <= n:\n",
    "                left = center_index - (L+j)\n",
    "                try:\n",
    "                    v_out.append(corpus[left])\n",
    "                    j+=1\n",
    "                except IndexError:\n",
    "                    break\n",
    "                    \n",
    "    return v_out\n",
    "\n",
    "\n",
    "def ocurrence_right(corpus, center, n):\n",
    "    v_out = []\n",
    "    words = iter(corpus)\n",
    "    \n",
    "    for word in range(0, len(corpus)):\n",
    "        w = next(words)\n",
    "        if (w == center):\n",
    "            center_index = word\n",
    "            j =1\n",
    "            \n",
    "            while j <= n:\n",
    "                try:\n",
    "                    v_out.append(corpus[center_index+j])\n",
    "                    j+=1\n",
    "                except IndexError:\n",
    "                    break\n",
    "                    \n",
    "    return v_out\n",
    "\n",
    "\n",
    "def process_corpus(corp, n, corpus_words, center_index):\n",
    "    \n",
    "    total_co_ocurrence = []\n",
    "     \n",
    "    \n",
    "    for document in corp:\n",
    "        \n",
    "        left_ocurrences = ocurrence_left(document, corpus_words[center_index], n)\n",
    "        right_ocurrences = ocurrence_right(document, corpus_words[center_index], n)\n",
    "        \n",
    "        total_co_ocurrence.append(left_ocurrences)\n",
    "        total_co_ocurrence.append(right_ocurrences)\n",
    "        \n",
    "    total_co_ocurrence = list(chain(*total_co_ocurrence))\n",
    "        \n",
    "    return total_co_ocurrence\n",
    "    \n",
    "    \n",
    "def vector_ocurrence(companion_words, corpus_words, w2i):\n",
    "    \n",
    "    \"\"\"Input:\n",
    "        Companion_words = Output from Process corpus, a vector made of words \n",
    "        Corpus_words = the ordered vocabulary, output from distinct_words\n",
    "        w2i : The mapping between word in vocabulary and index\n",
    "    \n",
    "       Output:\n",
    "        a vector made of integers placed in the index of the co ocurrence matrix\n",
    "    \n",
    "        example : [1, 0, 0, 0, 1, 1, 0, 0, 0, 1]\n",
    "    \n",
    "    \"\"\"\n",
    "    word_vector = [0]*len(corpus_words)\n",
    "    \n",
    "    for word in companion_words:\n",
    "        word_vector[w2i[word]] +=1\n",
    "    \n",
    "    return word_vector\n",
    "    \n",
    "    \n",
    "def co_ocurrence_matrix(corp, n, num_words, corpus_words, w2i):\n",
    "    \n",
    "    shape = (num_words, num_words)\n",
    "    ocurrence_words_mat = []\n",
    "    ocurrence_words_values = []\n",
    "    \n",
    "    for index_word in range(0, num_words):\n",
    "        ocurrence_word_vector = process_corpus(corp, n, corpus_words, center_index= index_word )\n",
    "        #vector_row = vector_ocurrence(companion_words, corpus_words, w2i)\n",
    "        ocurrence_words_mat.append(ocurrence_word_vector)\n",
    "        \n",
    "        \n",
    "    for tokens in ocurrence_words_mat:\n",
    "        vector_co_ocurrences = vector_ocurrence(tokens, corpus_words, w2i)\n",
    "        ocurrence_words_values.append(vector_co_ocurrences)\n",
    "        \n",
    "        \n",
    "        ### returning so far the words, i should put this one by one to the vector ocurrence function\n",
    "    \n",
    "    return ocurrence_words_mat, ocurrence_words_values\n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['All', 'glitters', 'well', 'ends'] \n",
      " [1, 0, 0, 0, 1, 1, 0, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "# Corpus sample\n",
    "corpus = [['START', 'All', 'that', 'glitters', \"isn't\", 'gold', 'END'], \\\n",
    "               ['START', \"All's\", 'well', 'that', 'ends', 'well', 'END']]\n",
    "\n",
    "distinct_output = ['All', \"All's\", 'END', 'START', 'ends', 'glitters', 'gold', \"isn't\", 'that', 'well']\n",
    "# Co-ocurrence parameters\n",
    "window = 1\n",
    "word_index = 8\n",
    "\n",
    "# word 2 index\n",
    "\n",
    "w2Index = dict(zip(distinct_output,[x for x in range(0,10) ] ))\n",
    "# pipeline\n",
    "\n",
    "ocurrence_vector = process_corpus(corpus, window, distinct_output, word_index )\n",
    "\n",
    "vector = vector_ocurrence(ocurrence_vector, distinct_output, w2Index)\n",
    "\n",
    "\n",
    "print(ocurrence_vector, \"\\n\", vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "words, values= co_ocurrence_matrix(corpus, window, 10, distinct_output, w2Index )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = np.array(values).reshape(10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 1],\n",
       "       [1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 1, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 1, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 1, 1, 0, 0, 0, 1],\n",
       "       [0, 1, 1, 0, 1, 0, 0, 0, 1, 0]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "Docstring process function\n",
    "    \n",
    "     \"\"\"input_arg\n",
    "        Corp = given corpus, can be made of list of lists \n",
    "        Corpus_words = the ordered vocabulary, output from distinct_words\n",
    "        center_index : the specific word from the vocabulary to be characterized by its companion words\n",
    "    \n",
    "     Output:\n",
    "        a vector made of the companion words\n",
    "    \n",
    "        example : ['All', 'glitters', 'well', 'ends']\n",
    "    \"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
